{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import csv\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"App_Name\").set('spark.executor.memory', '4G') \\\n",
    "    .set('spark.driver.memory', '45G').set('spark.driver.maxResultSize', '10G')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = defaultdict(lambda: defaultdict()) # dict[user][product] = score\n",
    "users = set() # len = 256059\n",
    "products = set() # len = 74258\n",
    "with open('Demo_data.csv', newline='') as csvfile: # 資料長度：568454 筆\n",
    "    rows = csv.reader(csvfile)\n",
    "    for i, row in islice(enumerate(rows), 1, None):\n",
    "#         print(row) # 'Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'\n",
    "        user_id = row[2]\n",
    "        product_id = row[1]\n",
    "        score = int(row[6])\n",
    "        score_dict[product_id][user_id] = score\n",
    "        users.add(user_id)\n",
    "        products.add(product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 item-item collaborative filtering\n",
    "#### Step1: 建立 matrix\n",
    "建立一個 matrix，存 user 對 product 的 score，格式：[(product, [(user, score), (user, score), ...])]\n",
    "\n",
    "#### Step2: 計算相似度\n",
    "三組 map-reduce</br>\n",
    "第一組：把每個 product score 做標準化（原本的值 - mean）</br>\n",
    "第二組：利用第一組的結果，計算兩兩 product 的 dot product 並加總 -> 存到 dot_value_dict[(product1, product2)] = value</br>\n",
    "第三組：利用第一組的結果，計算每個 product 的平方和 -> 存到 score_sqr_dict[product] = value\n",
    "\n",
    "計算相似度 -> similarity(product_1, product_2)</br>\n",
    "\n",
    "#### Step3: 預測分數\n",
    "由其他人的推薦結果，預測該 (user, product) 的 pair 預測分數是否超過 0.4 分，超過的留下，沒超過的刪除</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 建立 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(score_dict):\n",
    "    matrix = []\n",
    "    for product in score_dict:\n",
    "        scores = [(user, score) for user, score in score_dict[product].items()]\n",
    "        matrix.append((product, scores))\n",
    "    return matrix\n",
    "\n",
    "score_matrix = build_matrix(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: 計算相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將每個 product 分數做標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_product_standardization(line): # [('product_1', [('user_1', 1), ...]\n",
    "    maplist = []\n",
    "    scores = [score for (user, score) in line[1]]\n",
    "    avg = np.mean(scores)\n",
    "    for user, score in line[1]:\n",
    "        maplist.append((user, [(line[0], score-avg)]))\n",
    "    return maplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.parallelize(score_matrix).flatMap(mapper_product_standardization)\n",
    "lines_r = lines.reduceByKey(lambda x,y: x+y)\n",
    "# lines_r.collect() # [(user_id, [ (product_id, score), (product_id, score), ... ])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 計算 product 之間的 dot product\n",
    "方法：</br>\n",
    "前一步把同一個 column(user) 的資訊 group 在一起了，所以就把每個 product 兩兩配成一對把 score 相乘，在 reduce 時再把 dot 乘積相加起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_dot_product(line): # [('user_1', [('product_1', -2.6), ('product_3', -1.0), ('product_6', -1.6)]), ...]\n",
    "    maplist = []\n",
    "    for i, (product_1, score_1) in enumerate(line[1]):\n",
    "        for product_2, score_2 in islice(line[1], i+1, None):\n",
    "            maplist.append(((product_1, product_2), score_1*score_2))\n",
    "    return maplist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 product pair 的 dot product value 存進 dictionary 裡面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_value_dict = defaultdict() # dict[(product_id, product_id)] = score\n",
    "lines_dot = lines_r.flatMap(mapper_dot_product) # sc.parallelize(w)\n",
    "lines_dot_r = lines_dot.reduceByKey(lambda x,y: x+y)\n",
    "for line in lines_dot_r.collect(): # product score 平方和\n",
    "    if line[1] > 0: # 避免資料量過大，直接先把 dot value = 0 的過濾掉（代表相似度 < 0）\n",
    "        dot_value_dict[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 計算 product 的 score 平方和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_score_square(line): # [('user_1', [('product_1', -2.6), ('product_3', -1.0), ('product_6', -1.6)]), ...]\n",
    "    maplist = []\n",
    "    for product, score in line[1]:\n",
    "        maplist.append((product, score**2))\n",
    "    return maplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_sqr = lines_r.flatMap(mapper_score_square)\n",
    "lines_sqr_r = lines_sqr.reduceByKey(lambda x,y: x+y)\n",
    "# lines_sqr_r.collect() # product score 平方和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 product 的 score 平方和存進 dictionary 裡面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sqr_dict = defaultdict()\n",
    "for line in lines_sqr_r.collect():\n",
    "    score_sqr_dict[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 計算兩兩 product 的 相似度\n",
    "sum(dot乘積) / sqrt(product x 的平方和) * sqrt(product y 的平方和)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(product_1, product_2):\n",
    "    if (product_1, product_2) in dot_value_dict:\n",
    "        return dot_value_dict[(product_1, product_2)]/((score_sqr_dict[product_1]**0.5)*(score_sqr_dict[product_2]**0.5))\n",
    "    elif (product_2, product_1) in dot_value_dict:\n",
    "        return dot_value_dict[(product_2, product_1)]/((score_sqr_dict[product_1]**0.5)*(score_sqr_dict[product_2]**0.5))\n",
    "    else: # 兩個 product 完全沒有交集的狀態 -> dot value = 0 -> sim = 0\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sim = defaultdict(Counter)\n",
    "for i, product_1 in enumerate(score_matrix): # [('product_1', [('user_1', 1), ...]\n",
    "    for product_2 in islice(score_matrix, i+1, None):\n",
    "#         print(product_1[0], product_2[0], similarity(product_1[0], product_2[0]))\n",
    "        if similarity(product_1[0], product_2[0]) > 0: # 只儲存相似度 > 0 的狀況（小於 0 的資料沒用）\n",
    "            product_sim[product_1[0]][product_2[0]] = similarity(product_1[0], product_2[0])\n",
    "\n",
    "del score_sqr_dict, dot_value_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把 product similarity 寫進檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"product_similarity.txt\", 'w') as outputfile:\n",
    "    print(\"# product_1\", \"product_2\", \"similarity\", sep=\"\\t\", file=outputfile)\n",
    "    for i, product_1 in enumerate(product_sim):\n",
    "        for product_2, sim in product_sim[product_1].items():\n",
    "            print(product_1, product_2, sim, sep=\"\\t\", file=outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read product similarity file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sim = defaultdict(Counter)\n",
    "\n",
    "with open(\"product_similarity.txt\") as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        product_sim[ line.split()[0] ][ line.split()[1] ] = float(line.split()[2])\n",
    "        product_sim[ line.split()[1] ][ line.split()[0] ] = float(line.split()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: 預測分數\n",
    "\n",
    "先找出該 user 有評分的 product，再從中挑兩個分數最高的，計算：</br>\n",
    "r = (sim(p, p_1) * score_dict[user][p_1] + sim(p, p_2) * score_dict[user][p_2])/(sim(p, p_1)+sim(p, p_2))</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立以 user 為第一層的 dict，為預測分數的計算方便\n",
    "score_dict_reverse = defaultdict(Counter)\n",
    "for product in score_dict:\n",
    "    for user, score in score_dict[product].items():\n",
    "        score_dict_reverse[user][product] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(user, product):\n",
    "    # candidate: user 評過分的 product set\n",
    "    candidate = set([product for (product, score) in score_dict_reverse[user].most_common()])\n",
    "    weighted_score = 0; sim_sum = 0; count = 0\n",
    "    for (product_2, sim) in product_sim[product].most_common():\n",
    "        if sim < 0: # 不考慮相似度為負的的狀況（會導致預測分數超過 5）\n",
    "            break\n",
    "        if product_2 in candidate:\n",
    "            weighted_score += sim * score_dict_reverse[user][product_2]\n",
    "            sim_sum += sim\n",
    "            count += 1\n",
    "        if count >= 2:\n",
    "            break\n",
    "    return weighted_score/sim_sum if sim_sum > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算所有（user, product）pair 找出預測分數高的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_score_pairs = []\n",
    "for product in products:\n",
    "    for user in users:\n",
    "        if product in score_dict and user in score_dict[product]: # 評過分的\n",
    "            continue\n",
    "        else:\n",
    "            score = predict_score(user, product)\n",
    "            if score >= 4:\n",
    "                high_score_pairs.append(((user, product), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_score_pairs = sorted(high_score_pairs, key=lambda k: -k[1]) # 按 score 排序\n",
    "high_score_pairs = sorted(high_score_pairs, key=lambda k: k[0][0]) # 按 user_id 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high_score_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('A1B3SY3J47EXZE', 'B002CJARMI'), 5.0),\n",
       " (('A1BJHZE41QWBX6', 'B002CJARMI'), 5.0),\n",
       " (('A1KPKQZ1GMKAKO', 'B002CJARMI'), 5.0),\n",
       " (('A1ODDK3N8XC7UP', 'B002CJARMI'), 5.0),\n",
       " (('A1Z54EM24Y40LL', 'B00004RYGX'), 4.0),\n",
       " (('A1Z54EM24Y40LL', 'B00004CI84'), 4.0),\n",
       " (('A20EEWWSFMZ1PN', 'B007PA30TG'), 5.0),\n",
       " (('A20EEWWSFMZ1PN', 'B0047RQ9M0'), 5.0),\n",
       " (('A20EEWWSFMZ1PN', 'B003JA5KKS'), 5.0),\n",
       " (('A20EEWWSFMZ1PN', 'B007TJGZ54'), 5.0),\n",
       " (('A20EEWWSFMZ1PN', 'B001EYUE5M'), 5.0),\n",
       " (('A2AAA0U5QD5TGB', 'B002CJARMI'), 5.0),\n",
       " (('A2C5VLIJMDPWHI', 'B002CJARMI'), 5.0),\n",
       " (('A32207GKRIJYDI', 'B002CJARMI'), 5.0),\n",
       " (('A3L5V40F14R2GP', 'B002CJARMI'), 4.0),\n",
       " (('ALEABNMSVO1JI', 'B002CJARMI'), 5.0),\n",
       " (('AN71KYKFED796', 'B002CJARMI'), 5.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_score_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只計算 從 topic tag 以及 frequent Item set 產生出的推薦名單，篩選掉預測分數 < 4 分的 product</br>\n",
    "(因為直接計算所有沒有評過分的 user-product pair 運算量過大，會跑不完)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f21ff44a6861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user_foods_weichin.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user_possibuy_jamie.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfile1_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfile2_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"user_foods_weichin.json\") as file_1, open(\"user_possibuy_jamie.json\") as file_2:\n",
    "    file1_dict = json.load(file_1)\n",
    "    file2_dict = json.load(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_filt_dict = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for i, user in enumerate(file1_dict):\n",
    "    for tag, products in file1_dict[user].items():\n",
    "        filt = [ (product, predict_score(user, product)) for product in products if predict_score(user, product) >= 4]\n",
    "        filt = sorted(filt, key=lambda k: -k[1]) # 按 score 排序\n",
    "        tag_filt_dict[user][tag] = filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_filt_dict = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for i, user in enumerate(file1_dict):\n",
    "    for tag, products in file1_dict[user].items():\n",
    "        filt = [ (product, predict_score(user, product)) for product in products if predict_score(user, product) >= 4]\n",
    "        filt = sorted(filt, key=lambda k: -k[1]) # 按 score 排序\n",
    "        tag_filt_dict[user][tag] = filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256059\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('user_foods.pkl', 'rb') as f:\n",
    "    info = pickle.load(f)\n",
    "    print(len(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['A1Z54EM24Y40LL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqItem_filt_dict = defaultdict(list)\n",
    "\n",
    "for user, products in file2_dict.items():\n",
    "    filt = [ product for product in products if predict_score(user, product) >= 3.5]\n",
    "    freqItem_filt_dict[user] = filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 產生中間檔案 -> for MDA_merge.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"freqItem_filt.json\", 'w') as output:\n",
    "    json.dump(freqItem_filt_dict, output)\n",
    "    \n",
    "with open(\"tag_filt.json\", 'w') as output:\n",
    "    json.dump(tag_filt_dict, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
